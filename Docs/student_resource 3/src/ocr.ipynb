{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01measyocr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\easyocr\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01measyocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.7.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\easyocr\\easyocr.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_recognizer, get_text\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m group_text_box, get_image_list, calculate_md5, get_paragraph,\\\n\u001b[0;32m      5\u001b[0m                    download_and_unzip, printProgressBar, diff, reformat_input,\\\n\u001b[0;32m      6\u001b[0m                    make_rotated_img_list, set_result_with_confidence,\\\n\u001b[0;32m      7\u001b[0m                    reformat_input_batched, merge_to_free\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\easyocr\\recognition.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcudnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcudnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\torch\\__init__.py:1694\u001b[0m\n\u001b[0;32m   1691\u001b[0m py_int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;66;03m# Shared memory manager needs to know the exact location of manager executable\u001b[39;00m\n\u001b[1;32m-> 1694\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\torch\\cuda\\__init__.py:259\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m             \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[0;32m    256\u001b[0m             _queued_calls\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mcallable\u001b[39m, traceback\u001b[38;5;241m.\u001b[39mformat_stack()))\n\u001b[1;32m--> 259\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_check_capability\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m _lazy_call(_check_cubins)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeferredCudaCallError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\torch\\cuda\\__init__.py:256\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m     _lazy_seed_tracker\u001b[38;5;241m.\u001b[39mqueue_seed(\u001b[38;5;28mcallable\u001b[39m, traceback\u001b[38;5;241m.\u001b[39mformat_stack())\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     _queued_calls\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mcallable\u001b[39m, \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32md:\\Python\\Lib\\traceback.py:218\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Python\\Lib\\traceback.py:232\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 232\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32md:\\Python\\Lib\\traceback.py:395\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\traceback.py:438\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 438\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Python\\Lib\\traceback.py:323\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32md:\\Python\\Lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32md:\\Python\\Lib\\linecache.py:137\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mopen(fullname) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m--> 137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    results = reader.readtext(image)\n",
    "    extracted_text = ' '.join([result[1] for result in results])\n",
    "    return extracted_text\n",
    "\n",
    "def parse_measurement(text):\n",
    "    # Expanded pattern to catch more variations\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)\\s*(gram|centimetre|ounce|kilogram|g|cm|oz|kg|foot|ft|inch|in|metre|m|millimetre|mm|ton|t|volt|v|watt|w|kilovolt|kv|kilowatt|kw|pound|lb|yard|yd|millivolt|mv|microgram|μg)'\n",
    "    match = re.search(pattern, text.lower())\n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        # Normalize units\n",
    "        unit_map = {\n",
    "            'g': 'gram', 'cm': 'centimetre', 'oz': 'ounce', 'kg': 'kilogram',\n",
    "            'ft': 'foot', 'in': 'inch', 'm': 'metre', 'mm': 'millimetre',\n",
    "            't': 'ton', 'v': 'volt', 'w': 'watt', 'kv': 'kilovolt',\n",
    "            'kw': 'kilowatt', 'lb': 'pound', 'yd': 'yard', 'mv': 'millivolt',\n",
    "            'μg': 'microgram'\n",
    "        }\n",
    "        unit = unit_map.get(unit, unit)\n",
    "        return f\"{float(value)} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "image_folder = '../images'\n",
    "output_file = 'test_out_alterd.csv'\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['index', 'prediction'])\n",
    "    \n",
    "    for index, file in enumerate(tqdm(os.listdir(image_folder))):\n",
    "        image_path = os.path.join(image_folder, file)\n",
    "        try:\n",
    "            extracted_text = extract_text_from_image(image_path)\n",
    "            prediction = parse_measurement(extracted_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")\n",
    "            prediction = \"\"\n",
    "        writer.writerow([index, prediction])\n",
    "\n",
    "print(f\"CSV file '{output_file}' has been created with the predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of predictions: 54\n",
      "Number of non-empty predictions: 40\n",
      "Number of empty predictions: 14\n",
      "Percentage of non-empty predictions: 74.07%\n",
      "\n",
      "Example predictions:\n",
      "   index normalized_prediction\n",
      "0      0                      \n",
      "1      1                      \n",
      "2      2          2100.00 watt\n",
      "3      3                      \n",
      "4      4            55.00 watt\n",
      "5      5             0.00 inch\n",
      "6      6                      \n",
      "7      7                      \n",
      "8      8      50.00 centimetre\n",
      "9      9            6.75 pound\n",
      "\n",
      "Unit distribution in predictions:\n",
      "normalized_prediction\n",
      "              14\n",
      "centimetre    11\n",
      "metre          7\n",
      "inch           5\n",
      "watt           4\n",
      "pound          4\n",
      "volt           3\n",
      "gram           3\n",
      "ton            3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example predictions with metadata:\n",
      "   index                                         image_link  group_id  \\\n",
      "0      0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
      "1      1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
      "2      2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
      "3      3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
      "4      4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
      "5      5  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
      "6      6  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
      "7      7  https://m.media-amazon.com/images/I/11lshEUmCr...    156839   \n",
      "8      8  https://m.media-amazon.com/images/I/21+i52HRW4...    478357   \n",
      "9      9  https://m.media-amazon.com/images/I/21-LmSmehZ...    478357   \n",
      "\n",
      "  entity_name normalized_prediction  \n",
      "0      height                        \n",
      "1       width                        \n",
      "2      height          2100.00 watt  \n",
      "3       depth                        \n",
      "4       depth            55.00 watt  \n",
      "5      height             0.00 inch  \n",
      "6       width                        \n",
      "7      height                        \n",
      "8       width      50.00 centimetre  \n",
      "9      height            6.75 pound  \n",
      "\n",
      "Prediction analysis by group_id:\n",
      "          non_empty_predictions  total_samples  empty_predictions  \\\n",
      "group_id                                                            \n",
      "100951                        7              7                  0   \n",
      "102234                        2              2                  0   \n",
      "103688                        2              2                  0   \n",
      "104874                       80             80                  0   \n",
      "106003                      222            222                  0   \n",
      "...                         ...            ...                ...   \n",
      "995842                       24             24                  0   \n",
      "997176                      357            357                  0   \n",
      "997333                        2              2                  0   \n",
      "998545                      366            366                  0   \n",
      "999167                        2              2                  0   \n",
      "\n",
      "          non_empty_percentage  \n",
      "group_id                        \n",
      "100951                   100.0  \n",
      "102234                   100.0  \n",
      "103688                   100.0  \n",
      "104874                   100.0  \n",
      "106003                   100.0  \n",
      "...                        ...  \n",
      "995842                   100.0  \n",
      "997176                   100.0  \n",
      "997333                   100.0  \n",
      "998545                   100.0  \n",
      "999167                   100.0  \n",
      "\n",
      "[924 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normalize_prediction(pred):\n",
    "    if pd.isna(pred) or pred == \"\":\n",
    "        return \"\"\n",
    "    if isinstance(pred, (int, float)):\n",
    "        return f\"{pred:.2f}\"\n",
    "    parts = str(pred).split()\n",
    "    if len(parts) != 2:\n",
    "        return \"\"\n",
    "    try:\n",
    "        value = float(parts[0])\n",
    "        unit = parts[1]\n",
    "        return f\"{value:.2f} {unit}\"\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "# Load the predictions and ground truth\n",
    "predictions_df = pd.read_csv('test_out.csv')\n",
    "ground_truth_df = pd.read_csv('../dataset/test.csv')  # Adjust the path as needed\n",
    "\n",
    "# Ensure the dataframes are sorted by index\n",
    "predictions_df = predictions_df.sort_values('index').reset_index(drop=True)\n",
    "ground_truth_df = ground_truth_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "# Normalize predictions\n",
    "predictions_df['normalized_prediction'] = predictions_df['prediction'].apply(normalize_prediction)\n",
    "\n",
    "# Analyze predictions\n",
    "total_predictions = len(predictions_df)\n",
    "non_empty_predictions = (predictions_df['normalized_prediction'] != \"\").sum()\n",
    "empty_predictions = total_predictions - non_empty_predictions\n",
    "\n",
    "print(f\"Total number of predictions: {total_predictions}\")\n",
    "print(f\"Number of non-empty predictions: {non_empty_predictions}\")\n",
    "print(f\"Number of empty predictions: {empty_predictions}\")\n",
    "print(f\"Percentage of non-empty predictions: {(non_empty_predictions / total_predictions) * 100:.2f}%\")\n",
    "\n",
    "# Display some example predictions\n",
    "print(\"\\nExample predictions:\")\n",
    "print(predictions_df[['index', 'normalized_prediction']].head(10))\n",
    "\n",
    "# Analyze prediction units\n",
    "if non_empty_predictions > 0:\n",
    "    unit_counts = predictions_df['normalized_prediction'].apply(lambda x: x.split()[-1] if x else \"\").value_counts()\n",
    "    print(\"\\nUnit distribution in predictions:\")\n",
    "    print(unit_counts)\n",
    "\n",
    "# Join predictions with ground truth metadata\n",
    "merged_df = pd.merge(ground_truth_df, predictions_df[['index', 'normalized_prediction']], on='index', how='left')\n",
    "\n",
    "# Display some examples with metadata\n",
    "print(\"\\nExample predictions with metadata:\")\n",
    "print(merged_df[['index', 'image_link', 'group_id', 'entity_name', 'normalized_prediction']].head(10))\n",
    "\n",
    "# Analyze predictions by group_id\n",
    "group_analysis = merged_df.groupby('group_id').agg({\n",
    "    'normalized_prediction': lambda x: (x != \"\").sum(),\n",
    "    'index': 'count'\n",
    "}).rename(columns={'normalized_prediction': 'non_empty_predictions', 'index': 'total_samples'})\n",
    "group_analysis['empty_predictions'] = group_analysis['total_samples'] - group_analysis['non_empty_predictions']\n",
    "group_analysis['non_empty_percentage'] = (group_analysis['non_empty_predictions'] / group_analysis['total_samples']) * 100\n",
    "\n",
    "print(\"\\nPrediction analysis by group_id:\")\n",
    "print(group_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7137\n",
      "Precision: 1.0000\n",
      "Recall: 0.5549\n",
      "\n",
      "Total samples: 131187\n",
      "True Positives: 72796\n",
      "False Positives: 0\n",
      "False Negatives: 58391\n",
      "True Negatives: 0\n",
      "\n",
      "Example comparisons:\n",
      "   index entity_name normalized_prediction  expected_measurement  \\\n",
      "0      0      height                                           1   \n",
      "1      1       width      40.00 centimetre                     1   \n",
      "2      2      height      10.50 centimetre                     1   \n",
      "3      3       depth       6.00 centimetre                     1   \n",
      "4      4       depth           90.00 metre                     1   \n",
      "5      5      height              1.00 ton                     1   \n",
      "6      6       width      42.00 centimetre                     1   \n",
      "7      7      height             4.30 inch                     1   \n",
      "8      8       width                                           1   \n",
      "9      9      height                                           1   \n",
      "\n",
      "   has_prediction  \n",
      "0               0  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "5               1  \n",
      "6               1  \n",
      "7               1  \n",
      "8               0  \n",
      "9               0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dev\\AppData\\Local\\Temp\\ipykernel_15528\\2929409051.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comparison_df['expected_measurement'] = y_true\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def normalize_prediction(pred):\n",
    "    if pd.isna(pred) or pred == \"\":\n",
    "        return \"\"\n",
    "    if isinstance(pred, (int, float)):\n",
    "        return f\"{pred:.2f}\"\n",
    "    parts = str(pred).split()\n",
    "    if len(parts) != 2:\n",
    "        return \"\"\n",
    "    try:\n",
    "        value = float(parts[0])\n",
    "        unit = parts[1]\n",
    "        return f\"{value:.2f} {unit}\"\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "predictions_df = pd.read_csv('test_out3_evening.csv')\n",
    "ground_truth_df = pd.read_csv('../dataset/test.csv')  # Adjust the path as needed\n",
    "\n",
    "\n",
    "predictions_df = predictions_df.sort_values('index').reset_index(drop=True)\n",
    "ground_truth_df = ground_truth_df.sort_values('index').reset_index(drop=True)\n",
    "\n",
    "\n",
    "predictions_df['normalized_prediction'] = predictions_df['prediction'].apply(normalize_prediction)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(ground_truth_df, predictions_df[['index', 'normalized_prediction']], on='index', how='left')\n",
    "\n",
    "# Create binary labels\n",
    "# Assume that if 'entity_name' is not empty, there should be a measurement\n",
    "y_true = (merged_df['entity_name'] != \"\").astype(int)\n",
    "y_pred = (merged_df['normalized_prediction'] != \"\").astype(int)\n",
    "\n",
    "# Calculate F1 score, precision, and recall\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\") \n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Additional analysis\n",
    "total_samples = len(merged_df)\n",
    "true_positives = ((y_true == 1) & (y_pred == 1)).sum()\n",
    "false_positives = ((y_true == 0) & (y_pred == 1)).sum()\n",
    "false_negatives = ((y_true == 1) & (y_pred == 0)).sum()\n",
    "true_negatives = ((y_true == 0) & (y_pred == 0)).sum()\n",
    "\n",
    "print(f\"\\nTotal samples: {total_samples}\")\n",
    "print(f\"True Positives: {true_positives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "\n",
    "# Display some example comparisons\n",
    "print(\"\\nExample comparisons:\")\n",
    "comparison_df = merged_df[['index', 'entity_name', 'normalized_prediction']]\n",
    "comparison_df['expected_measurement'] = y_true\n",
    "comparison_df['has_prediction'] = y_pred\n",
    "print(comparison_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/54 [00:00<00:04, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 41-NCxNuBxL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 417NJrPEk+L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 417SThj+SrL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 41ADVPQgZOL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6/54 [00:00<00:03, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 41nblnEkJ3L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 41o3iis9E7L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 41pvwR9GbaL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 8/54 [00:00<00:03, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 41uwo4PVnuL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 41ygXRvf8lL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 10/54 [00:00<00:04,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 41zgjN+zW3L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51+oHGvSvuL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 13/54 [00:01<00:04,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51-WIOx5pxL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 510xYFNYQ8L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 514bY8c4ZIL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 16/54 [00:01<00:04,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 514pScQdlCL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51BEuVR4ZzL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 18/54 [00:02<00:04,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51bEy0J5wLL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51cPZYLk2YL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 20/54 [00:02<00:04,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51EBBqNOJ1L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51fAzxNm+cL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 22/54 [00:02<00:04,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51FSlaVlejL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51H+mX2Wk7L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51jTe522S2L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 26/54 [00:03<00:03,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51kdBAv6ImL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51KykmLgc0L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51l6c6UcRZL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 28/54 [00:03<00:02, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51oaOP8qJlL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51P0IuT6RsL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51r7U52rh7L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 32/54 [00:03<00:01, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 51Su6zXkAsL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51tEop-EBJL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51vwYpDz2tL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 51y79cwGJFL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 613P5cxQH4L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 35/54 [00:04<00:02,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 614hn5uX9MS.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 36/54 [00:04<00:03,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 615Cjzm6pyL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 37/54 [00:04<00:03,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 61C+fwVD6dL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 38/54 [00:05<00:03,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 61E2XRNSdYL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 39/54 [00:05<00:03,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 61G8bvWOb-L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 40/54 [00:05<00:03,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 61lX6IP1SVL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 61O+Yi09tyL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 42/54 [00:06<00:03,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71afEPoRGsL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 43/54 [00:06<00:03,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71eCfiIG-AL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 44/54 [00:06<00:03,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71fWddA0+yL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 46/54 [00:07<00:02,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71Qk6hR9-WL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "Error processing 71ta6wY3HtL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 47/54 [00:08<00:02,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71UN1IxKp4L.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 48/54 [00:08<00:02,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71UYDq4nfnL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 49/54 [00:08<00:01,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71v+pim0lfL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 50/54 [00:09<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 71WAjPMQDWL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 51/54 [00:09<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 81aZ2ozp1GL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 52/54 [00:10<00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 81IYdOV0mVL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 53/54 [00:11<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 81PG3ea0MOL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:12<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 81qUmRUUTTL.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
      "CSV file 'test_out_tesseract.csv' has been created with the predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "def parse_measurement(text):\n",
    "    # Expanded pattern to catch more variations\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)\\s*(gram|centimetre|ounce|kilogram|g|cm|oz|kg|foot|ft|inch|in|metre|m|millimetre|mm|ton|t|volt|v|watt|w|kilovolt|kv|kilowatt|kw|pound|lb|yard|yd|millivolt|mv|microgram|μg)'\n",
    "    match = re.search(pattern, text.lower())\n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        # Normalize units\n",
    "        unit_map = {\n",
    "            'g': 'gram', 'cm': 'centimetre', 'oz': 'ounce', 'kg': 'kilogram',\n",
    "            'ft': 'foot', 'in': 'inch', 'm': 'metre', 'mm': 'millimetre',\n",
    "            't': 'ton', 'v': 'volt', 'w': 'watt', 'kv': 'kilovolt',\n",
    "            'kw': 'kilowatt', 'lb': 'pound', 'yd': 'yard', 'mv': 'millivolt',\n",
    "            'μg': 'microgram'\n",
    "        }\n",
    "        unit = unit_map.get(unit, unit)\n",
    "        return f\"{float(value)} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "image_folder = '../images'\n",
    "output_file = 'test_out_tesseract.csv'\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['index', 'prediction'])\n",
    "\n",
    "    for index, file in enumerate(tqdm(os.listdir(image_folder))):\n",
    "        image_path = os.path.join(image_folder, file)\n",
    "        try:\n",
    "            extracted_text = extract_text_from_image(image_path)\n",
    "            prediction = parse_measurement(extracted_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")\n",
    "            prediction = \"\"\n",
    "        writer.writerow([index, prediction])\n",
    "\n",
    "print(f\"CSV file '{output_file}' has been created with the predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in d:\\python\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dev\\appdata\\roaming\\python\\python312\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in d:\\python\\lib\\site-packages (from pytesseract) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between test.csv and test_out.csv row counts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Assuming the column for ground truth is 'GT' and for output is 'OUT'\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m GT \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m OUT \u001b[38;5;241m=\u001b[39m test_out_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOUT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Initialize counts\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GT'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ground truth and model output CSVs\n",
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "test_out_df = pd.read_csv('test_out3_all_indexes.csv')\n",
    "\n",
    "# Ensure both CSVs have the same length and the same columns\n",
    "if len(test_df) != len(test_out_df):\n",
    "    raise ValueError(\"Mismatch between test.csv and test_out.csv row counts.\")\n",
    "\n",
    "# Assuming the column for ground truth is 'GT' and for output is 'OUT'\n",
    "GT = test_df['GT']\n",
    "OUT = test_out_df['OUT']\n",
    "\n",
    "# Initialize counts\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "true_negatives = 0\n",
    "\n",
    "# Iterate over the dataset\n",
    "for gt, out in zip(GT, OUT):\n",
    "    if out != \"\" and gt != \"\" and out == gt:\n",
    "        true_positives += 1\n",
    "    elif out != \"\" and gt != \"\" and out != gt:\n",
    "        false_positives += 1\n",
    "    elif out != \"\" and gt == \"\":\n",
    "        false_positives += 1\n",
    "    elif out == \"\" and gt != \"\":\n",
    "        false_negatives += 1\n",
    "    elif out == \"\" and gt == \"\":\n",
    "        true_negatives += 1\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "if precision + recall == 0:\n",
    "    f1_score = 0\n",
    "else:\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Output results\n",
    "print(f\"True Positives: {true_positives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load and inspect the two CSV files to understand their structure, so we can implement the F1 score algorithm based on the provided logic.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the two files to inspect their contents\n",
    "ground_truth_file = '/mnt/data/sample_test.csv'\n",
    "output_file = '/mnt/data/sample_test_out.csv'\n",
    "\n",
    "# Load both files\n",
    "ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "output_df = pd.read_csv(output_file)\n",
    "\n",
    "# Display the first few rows of both files to understand their structure\n",
    "ground_truth_df.head(), output_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 72852\n",
      "False Positives: 0\n",
      "False Negatives: 58335\n",
      "True Negatives: 0\n",
      "Precision: 0.0000000000\n",
      "Recall: 0.0000000000\n",
      "F1 Score: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# Merge the ground truth and prediction dataframes on the index\n",
    "import pandas as pd\n",
    "\n",
    "# Load the two files to inspect their contents\n",
    "ground_truth_file = '../dataset/test.csv'\n",
    "output_file = 'test_out3_all_indexes.csv'\n",
    "\n",
    "# Load both files\n",
    "ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "output_df = pd.read_csv(output_file)\n",
    "\n",
    "# Display the first few rows of both files to understand their structure\n",
    "ground_truth_df.head(), output_df.head()\n",
    "\n",
    "\n",
    "merged_df = pd.merge(ground_truth_df[['index', 'entity_name']], output_df[['index', 'prediction']], on='index')\n",
    "\n",
    "# Initialize counts for TP, FP, FN, and TN\n",
    "TP = FP = FN = TN = 0\n",
    "\n",
    "# Iterate over the merged dataframe and apply the logic\n",
    "for _, row in merged_df.iterrows():\n",
    "    GT = row['entity_name']\n",
    "    OUT = row['prediction']\n",
    "    \n",
    "    if pd.notna(GT) and pd.notna(OUT):\n",
    "        if GT == OUT:\n",
    "            TP += 1  # True Positive: OUT != \"\" and GT != \"\" and OUT == GT\n",
    "        else:\n",
    "            FP += 1  # False Positive: OUT != \"\" and GT != \"\" and OUT != GT\n",
    "    elif pd.isna(GT) and pd.notna(OUT):\n",
    "        FP += 1  # False Positive: OUT != \"\" and GT == \"\"\n",
    "    elif pd.notna(GT) and pd.isna(OUT):\n",
    "        FN += 1  # False Negative: OUT == \"\" and GT != \"\"\n",
    "    elif pd.isna(GT) and pd.isna(OUT):\n",
    "        TN += 1  # True Negative: OUT == \"\" and GT == \"\"\n",
    "\n",
    "# Calculate Precision, Recall, and F1 score\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "TP, FP, FN, TN, precision, recall, f1_score\n",
    "\n",
    "print(f\"True Positives: {true_positives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"Precision: {precision:.10f}\")  # Updated to 10 decimal points\n",
    "print(f\"Recall: {recall:.10f}\")        # Updated to 10 decimal points\n",
    "print(f\"F1 Score: {f1_score:.10f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0, FP: 131187, FN: 0\n",
      "True Positives: 0\n",
      "False Positives: 131187\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Precision: 0.0000000000\n",
      "Recall: 0.0000000000\n",
      "F1 Score: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ground truth and model output CSVs\n",
    "test_df = pd.read_csv('../dataset/test.csv')  # Adjust the path as necessary\n",
    "test_out_df = pd.read_csv('test_out3_all_indexes.csv')  # Adjust the path as necessary\n",
    "\n",
    "# Ensure both CSVs have the same length and the same columns\n",
    "if len(test_df) != len(test_out_df):\n",
    "    raise ValueError(\"Mismatch between test.csv and test_out.csv row counts.\")\n",
    "\n",
    "# Change the variable assignments to match your DataFrame structure\n",
    "GT = test_df['entity_name']  # Assuming 'entity_name' is the column for ground truth\n",
    "OUT = test_out_df['prediction']  # Assuming 'prediction' is the column for model output\n",
    "\n",
    "# Initialize counts\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "true_negatives = 0\n",
    "\n",
    "# Iterate over the dataset\n",
    "for gt, out in zip(GT, OUT):\n",
    "    if out != \"\" and gt != \"\" and out == gt:\n",
    "        true_positives += 1\n",
    "    elif out != \"\" and gt != \"\" and out != gt:\n",
    "        false_positives += 1\n",
    "    elif out != \"\" and gt == \"\":\n",
    "        false_positives += 1\n",
    "    elif out == \"\" and gt != \"\":\n",
    "        false_negatives += 1\n",
    "    elif out == \"\" and gt == \"\":\n",
    "        true_negatives += 1\n",
    "\n",
    "# Debugging counts\n",
    "print(f\"TP: {true_positives}, FP: {false_positives}, FN: {false_negatives}\")\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "if precision + recall == 0:\n",
    "    f1_score = 0\n",
    "else:\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Output results\n",
    "print(f\"True Positives: {true_positives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"Precision: {precision:.10f}\")  # Updated to 10 decimal points\n",
    "print(f\"Recall: {recall:.10f}\")        # Updated to 10 decimal points\n",
    "print(f\"F1 Score: {f1_score:.10f}\")    # Updated to 10 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth DataFrame:\n",
      "   index                                         image_link  group_id  \\\n",
      "0      0  https://m.media-amazon.com/images/I/41-NCxNuBx...    658003   \n",
      "1      1  https://m.media-amazon.com/images/I/41-NCxNuBx...    658003   \n",
      "2      2  https://m.media-amazon.com/images/I/417NJrPEk+...    939426   \n",
      "3      3  https://m.media-amazon.com/images/I/417SThj+Sr...    276700   \n",
      "4      4  https://m.media-amazon.com/images/I/417SThj+Sr...    276700   \n",
      "\n",
      "                     entity_name  \n",
      "0                          width  \n",
      "1                          depth  \n",
      "2  maximum_weight_recommendation  \n",
      "3                        voltage  \n",
      "4                        wattage  \n",
      "\n",
      "Prediction DataFrame:\n",
      "   index        prediction\n",
      "0      0         21.9 foot\n",
      "1      1           10 foot\n",
      "2      2               NaN\n",
      "3      3   289.52 kilovolt\n",
      "4      4  1078.99 kilowatt\n",
      "\n",
      "Merged DataFrame:\n",
      "   index                    entity_name        prediction\n",
      "0      0                          width         21.9 foot\n",
      "1      1                          depth           10 foot\n",
      "2      2  maximum_weight_recommendation               NaN\n",
      "3      3                        voltage   289.52 kilovolt\n",
      "4      4                        wattage  1078.99 kilowatt\n",
      "\n",
      "True Positives (TP): 0\n",
      "False Positives (FP): 88\n",
      "False Negatives (FN): 0\n",
      "True Negatives (TN): 0\n",
      "\n",
      "Precision: 0.0000000000\n",
      "Recall: 0.0000000000\n",
      "F1 Score: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ground truth and model output CSVs\n",
    "test_df = pd.read_csv('../dataset/sample_test.csv')\n",
    "test_out_df = pd.read_csv('../dataset/sample_test_out.csv')\n",
    "\n",
    "# Debugging: Print the first few rows of the input dataframes\n",
    "print(\"Ground Truth DataFrame:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nPrediction DataFrame:\")\n",
    "print(test_out_df.head())\n",
    "\n",
    "# Merge the dataframes on the 'index' column\n",
    "merged_df = pd.merge(test_df[['index', 'entity_name']], test_out_df, on='index')\n",
    "\n",
    "# Debugging: Print the first few rows of the merged dataframe\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Extract the ground truth and predictions\n",
    "GT = merged_df['entity_name']\n",
    "OUT = merged_df['prediction']\n",
    "\n",
    "# Initialize counts using vectorized operations\n",
    "true_positives = ((OUT != \"\") & (GT != \"\") & (OUT == GT)).sum()\n",
    "false_positives = ((OUT != \"\") & (GT != \"\") & (OUT != GT)).sum() + ((OUT != \"\") & (GT == \"\")).sum()\n",
    "false_negatives = ((OUT == \"\") & (GT != \"\")).sum()\n",
    "true_negatives = ((OUT == \"\") & (GT == \"\")).sum()\n",
    "\n",
    "# Debugging: Print the counts\n",
    "print(f\"\\nTrue Positives (TP): {true_positives}\")\n",
    "print(f\"False Positives (FP): {false_positives}\")\n",
    "print(f\"False Negatives (FN): {false_negatives}\")\n",
    "print(f\"True Negatives (TN): {true_negatives}\")\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "if precision + recall == 0:\n",
    "    f1_score = 0\n",
    "else:\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Output results\n",
    "print(f\"\\nPrecision: {precision:.10f}\")\n",
    "print(f\"Recall: {recall:.10f}\")\n",
    "print(f\"F1 Score: {f1_score:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
